{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "UnXoqEc9ds24"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "q2S_zKlyf4qd"
      },
      "outputs": [],
      "source": [
        "complete_df = pd.read_excel('data_okeanos.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "-VuEps4qoZyG"
      },
      "outputs": [],
      "source": [
        "def opschonen(data):\n",
        "    ### Onnodige kolommen verwijderen\n",
        "    complete_df = pd.read_excel(data)\n",
        "    clean_col_df = complete_df.drop(columns=['datum', 'ploeg', 'zone', 'intervaltype', 'interval_afstand', 'aantal_intervallen', 'interval_tijd', 'interval_nummer', 'rust', 'machine', 'spm'], errors='ignore')\n",
        "\n",
        "    ### Lege strings omzetten naar NaN in de specifieke kolommen\n",
        "    clean_col_df['500_split'] = clean_col_df['500_split'].replace('', pd.NA)\n",
        "    clean_col_df['2k tijd'] = clean_col_df['2k tijd'].replace('', pd.NA)\n",
        "\n",
        "    ### Alleen rijen met lege '500_split' of '2k tijd' verwijderen\n",
        "    clean_row_df = clean_col_df.dropna(subset=['500_split', '2k tijd'])\n",
        "    clean_row_df.dropna(how='any',inplace=True)\n",
        "\n",
        "    ### Maak een kopie voor opschonen\n",
        "    clean_df = clean_row_df.copy()\n",
        "    clean_df.dropna(subset=['500_split', '2k tijd'])\n",
        "\n",
        "    ### Komma's naar punten veranderen in ‘500_split’ en ‘2k tijd’ columns en uren veranderen naar minuten (00:01:11.11 wordt 1:11.11)\n",
        "    for col in ['500_split', '2k tijd']:\n",
        "        clean_df[col] = clean_df[col].astype(str).str.strip()\n",
        "        clean_df[col] = clean_df[col].str.replace(',', '.', regex=False)\n",
        "        clean_df[col] = clean_df[col].str.lstrip('0')\n",
        "\n",
        "        # clean_df[col] = clean_df[col].astype(str).str.strip()\n",
        "        # clean_df[col] = clean_df[col].str.replace(',', '.', regex=False)\n",
        "        # clean_df[col] = clean_df[col].str.lstrip('0')\n",
        "        # clean_df[col] = clean_df[col].str.replace('^0:0', '', regex=True)\n",
        "\n",
        "    ### Verander 'trainingype' naar 'trainingtype'\n",
        "    clean_df = clean_df.rename(columns={'trainingype': 'trainingtype'})\n",
        " \n",
        "    return clean_df\n",
        "\n",
        "\n",
        "### de minuten veranderen naar seconden\n",
        "\n",
        "def time_to_seconds(time_str):\n",
        "    if pd.isna(time_str):\n",
        "        return None\n",
        "    try:\n",
        "        minutes, seconds = map(float, str(time_str).split(':'))\n",
        "        # print('GOOD:', time_str)\n",
        "        return minutes * 60 + seconds\n",
        "    except ValueError:\n",
        "        # print('ERROR:', time_str)\n",
        "        return None\n",
        "\n",
        "def verander_omzetting_seconden(docu):\n",
        "    docu['500_split'] = docu['500_split'].apply(time_to_seconds)\n",
        "    docu['2k tijd'] = docu['2k tijd'].apply(time_to_seconds)\n",
        "    return docu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      ervaring geslacht gewichtsklasse   naam trainingtype      500_split  \\\n",
            "0          1.0        M              Z    z47         5x5'         1:44.6   \n",
            "1          1.0        M              Z    z47         5x5'         1:44.7   \n",
            "2          1.0        M              Z    z47         5x5'         1:44.3   \n",
            "3          1.0        M              Z    z47         5x5'         1:44.0   \n",
            "4          1.0        M              Z    z47         5x5'         1:44.1   \n",
            "...        ...      ...            ...    ...          ...            ...   \n",
            "7433       1.0        M              L  Z2522       1x2000  :06:37.400000   \n",
            "7434       1.0        M              L  Z2521       1x2000  :06:57.500000   \n",
            "7435       1.0        M              L  Z2520       1x2000         :07:05   \n",
            "7436       1.0        M              Z  Z2517       1x2000         6:39.1   \n",
            "7437       1.0        M              Z  Z2519       1x2000         6:17.0   \n",
            "\n",
            "      2k tijd   2k datum  \n",
            "0      6:19.9 2018-12-08  \n",
            "1      6:19.9 2018-12-08  \n",
            "2      6:19.9 2018-12-08  \n",
            "3      6:19.9 2018-12-08  \n",
            "4      6:19.9 2018-12-08  \n",
            "...       ...        ...  \n",
            "7433   6:37.4 2024-12-15  \n",
            "7434   6:57.5 2024-12-15  \n",
            "7435  7:05.00 2024-12-15  \n",
            "7436   6:39.1 2024-12-15  \n",
            "7437   6:17.0 2024-12-15  \n",
            "\n",
            "[4610 rows x 8 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8539/3565298680.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_row_df.dropna(how='any',inplace=True)\n"
          ]
        }
      ],
      "source": [
        "roeien_opgeschoond = opschonen('data_okeanos.xlsx')\n",
        "print(roeien_opgeschoond)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixobhcnk45Sw",
        "outputId": "ff8e9c22-1ed2-4211-8f2e-8d35f9bba761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      ervaring geslacht gewichtsklasse   naam trainingtype  500_split  \\\n",
            "0          1.0        M              Z    z47         5x5'      104.6   \n",
            "1          1.0        M              Z    z47         5x5'      104.7   \n",
            "2          1.0        M              Z    z47         5x5'      104.3   \n",
            "3          1.0        M              Z    z47         5x5'      104.0   \n",
            "4          1.0        M              Z    z47         5x5'      104.1   \n",
            "...        ...      ...            ...    ...          ...        ...   \n",
            "7212       0.0        V              L  D2511       1x1500      120.4   \n",
            "7419       1.0        M              Z  Z2522       2x2000      387.9   \n",
            "7420       1.0        M              Z  Z2522       2x2000      406.4   \n",
            "7436       1.0        M              Z  Z2517       1x2000      399.1   \n",
            "7437       1.0        M              Z  Z2519       1x2000      377.0   \n",
            "\n",
            "      2k tijd   2k datum  \n",
            "0       379.9 2018-12-08  \n",
            "1       379.9 2018-12-08  \n",
            "2       379.9 2018-12-08  \n",
            "3       379.9 2018-12-08  \n",
            "4       379.9 2018-12-08  \n",
            "...       ...        ...  \n",
            "7212    484.1 2024-12-15  \n",
            "7419    382.8 2024-12-15  \n",
            "7420    382.8 2024-12-15  \n",
            "7436    399.1 2024-12-15  \n",
            "7437    377.0 2024-12-15  \n",
            "\n",
            "[4316 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "dataframe_op_sec = verander_omzetting_seconden(roeien_opgeschoond)\n",
        "dataframe_op_sec.dropna(inplace=True)\n",
        "print(dataframe_op_sec)\n",
        "\n",
        "# dataframe_op_sec.to_csv('verschoond_dataframe.csv', index=False)\n",
        "# verschoond_dataframe = pd.read_csv('verschoond_dataframe.csv')\n",
        "# verschoond_dataframe.to_excel('verschoond_dataframe.xlsx', index=None, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ervaring geslacht gewichtsklasse naam trainingtype  500_split  2k tijd  \\\n",
            "0         1        M              Z  z47         5x5'      104.6    379.9   \n",
            "1         1        M              Z  z47         5x5'      104.7    379.9   \n",
            "2         1        M              Z  z47         5x5'      104.3    379.9   \n",
            "3         1        M              Z  z47         5x5'      104.0    379.9   \n",
            "4         1        M              Z  z47         5x5'      104.1    379.9   \n",
            "\n",
            "    2k datum binary_trainingtype binary_geslacht binary_gewichtsklasse  \n",
            "0 2018-12-08                   0               0                     1  \n",
            "1 2018-12-08                   0               0                     1  \n",
            "2 2018-12-08                   0               0                     1  \n",
            "3 2018-12-08                   0               0                     1  \n",
            "4 2018-12-08                   0               0                     1  \n",
            "Trainingtype Mapping: {\"5x5'\": '0', \"3x15'\": '1', \"3x20'\": '10', '3x2000m': '11', '6000m': '100', '4x1500m': '101', '3x1000m': '110', '6x500m': '111', '1500m': '1000', \"1'\": '1001', '2000m': '1010', \"30'\": '1011', '2x2000m': '1100', \"8x5'\": '1101', '3x4000m': '1110', \"4x8'\": '1111', \"3x10'\": '10000', '1000m': '10001', '1500m+500m': '10010', \"8x3'\": '10011', '4x750m': '10100', '2x2000m+500m': '10101', '1000m+500m': '10110', \"4x5'\": '10111', \"3x12'\": '11000', \"2x25'\": '11001', '8x500m': '11010', '100m': '11011', '500m': '11100', \"57'\": '11101', \"3x7'\": '11110', \"3x8'\": '11111', nan: '100000', '4x500m': '100001', '3x3000m': '100010', \"7x3'\": '100011', \"2x19'\": '100100', '2x3000m': '100101', '6x750m': '100110', '1500m+750m': '100111', \"3x11'\": '101000', \"6x6'\": '101001', \"3x13'\": '101010', \"5x8'\": '101011', \"20'\": '101100', \"2x10'\": '101101', '1x1500m': '101110', '1x2000m': '101111'}\n",
            "Geslacht Mapping: {'M': '0', 'V': '1'}\n",
            "Gewichtsklasse Mapping: {'L': '0', 'Z': '1'}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def omzetten_binair(df):\n",
        "\n",
        "    ### de trainingtypes zo veranderen dat ze makkelijker te gebruiken zijn\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(r\"/[a-zA-Z0-9']{3,}\", \"\", regex=True)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\"HOP+3x1'r\", \"57'\", regex=False)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\" \", \"\", regex=False)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\"r\", \"\", regex=False)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(r\"minuutjes\", \"1'\", regex=True)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(r'\\b(?:\\d+x)+1\\'', \"1'\", regex=True)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(r'(\\d+x\\d+)(?!m|\\')$', r'\\1m', regex=True)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(r'\\b(\\d{4})(?!m|\\')\\b', r'\\1m', regex=True)\n",
        "\n",
        "    ### zet de trainingtypes om naar binaire getallen\n",
        "    unique_trainingtypes = df['trainingtype'].unique()\n",
        "    trainingtype_to_decimal = {trainingtype: i for i, trainingtype in enumerate(unique_trainingtypes)}\n",
        "    trainingtype_mapping = {trainingtype: bin(i)[2:] for trainingtype, i in trainingtype_to_decimal.items()}\n",
        "    df['binary_trainingtype'] = df['trainingtype'].map(trainingtype_mapping)\n",
        "\n",
        "    ### zet de geslachten om naar binaire getallen\n",
        "    geslacht_binarizer = LabelBinarizer()\n",
        "    geslacht_binarizer.fit(df['geslacht'])\n",
        "    geslacht_mapping = {str(label): bin(i)[2:] for i, label in enumerate(geslacht_binarizer.classes_)}\n",
        "    df['binary_geslacht'] = df['geslacht'].map(geslacht_mapping)\n",
        "\n",
        "    ### zet de gewichtsklasses om naar binaire getallen\n",
        "    gewichtsklasse_binarizer = LabelBinarizer()\n",
        "    gewichtsklasse_binarizer.fit(df['gewichtsklasse'])\n",
        "    gewichtsklasse_mapping = {str(label): bin(i)[2:] for i, label in enumerate(gewichtsklasse_binarizer.classes_)}\n",
        "    df['binary_gewichtsklasse'] = df['gewichtsklasse'].map(gewichtsklasse_mapping)\n",
        "\n",
        "    df['ervaring'] = df['ervaring'].astype(int)\n",
        "\n",
        "    return df, trainingtype_mapping, geslacht_mapping, gewichtsklasse_mapping\n",
        "\n",
        "new_dataframe, trainingtype_mapping, geslacht_mapping, gewichtsklasse_mapping = omzetten_binair(dataframe_op_sec)\n",
        "\n",
        "print(new_dataframe.head())\n",
        "print(\"Trainingtype Mapping:\", trainingtype_mapping)\n",
        "print(\"Geslacht Mapping:\", geslacht_mapping)\n",
        "print(\"Gewichtsklasse Mapping:\", gewichtsklasse_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tweek_naar_split(data):\n",
        "    mask = data['500_split'] > 300\n",
        "    data.loc[mask, '500_split'] = data.loc[mask, '500_split'] / 4\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ervaring  500_split  2k tijd binary_trainingtype binary_geslacht  \\\n",
            "0         1      104.6    379.9                   0               0   \n",
            "1         1      104.7    379.9                   0               0   \n",
            "2         1      104.3    379.9                   0               0   \n",
            "3         1      104.0    379.9                   0               0   \n",
            "4         1      104.1    379.9                   0               0   \n",
            "\n",
            "  binary_gewichtsklasse  \n",
            "0                     1  \n",
            "1                     1  \n",
            "2                     1  \n",
            "3                     1  \n",
            "4                     1  \n"
          ]
        }
      ],
      "source": [
        "def remove_outliers(data):\n",
        "  alles = tweek_naar_split(data)\n",
        "  alles = alles[alles['500_split'] >= 80]\n",
        "  return alles\n",
        "\n",
        "def total_clean(data):\n",
        "    \n",
        "    columns_to_drop = ['geslacht', 'gewichtsklasse', 'trainingtype', 'naam', '2k datum']\n",
        "    cleaned_data = data.drop(columns=columns_to_drop)\n",
        "    \n",
        "    return cleaned_data\n",
        "\n",
        "almost_clean_df = remove_outliers(new_dataframe)\n",
        "final_df = total_clean(almost_clean_df)\n",
        "print(final_df.head())\n",
        "final_df.to_csv('final_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   500_split  2k tijd  geslacht_M  geslacht_V  gewichtsklasse_L  \\\n",
            "0      104.6    379.9         1.0         0.0               0.0   \n",
            "1      104.7    379.9         1.0         0.0               0.0   \n",
            "2      104.3    379.9         1.0         0.0               0.0   \n",
            "3      104.0    379.9         1.0         0.0               0.0   \n",
            "4      104.1    379.9         1.0         0.0               0.0   \n",
            "\n",
            "   gewichtsklasse_Z  ervaring_0  ervaring_1  binary_trainingtype_0  \\\n",
            "0               1.0         0.0         1.0                    1.0   \n",
            "1               1.0         0.0         1.0                    1.0   \n",
            "2               1.0         0.0         1.0                    1.0   \n",
            "3               1.0         0.0         1.0                    1.0   \n",
            "4               1.0         0.0         1.0                    1.0   \n",
            "\n",
            "   binary_trainingtype_1  ...  binary_trainingtype_1101  \\\n",
            "0                    0.0  ...                       0.0   \n",
            "1                    0.0  ...                       0.0   \n",
            "2                    0.0  ...                       0.0   \n",
            "3                    0.0  ...                       0.0   \n",
            "4                    0.0  ...                       0.0   \n",
            "\n",
            "   binary_trainingtype_11010  binary_trainingtype_11011  \\\n",
            "0                        0.0                        0.0   \n",
            "1                        0.0                        0.0   \n",
            "2                        0.0                        0.0   \n",
            "3                        0.0                        0.0   \n",
            "4                        0.0                        0.0   \n",
            "\n",
            "   binary_trainingtype_111  binary_trainingtype_1110  \\\n",
            "0                      0.0                       0.0   \n",
            "1                      0.0                       0.0   \n",
            "2                      0.0                       0.0   \n",
            "3                      0.0                       0.0   \n",
            "4                      0.0                       0.0   \n",
            "\n",
            "   binary_trainingtype_11100  binary_trainingtype_11101  \\\n",
            "0                        0.0                        0.0   \n",
            "1                        0.0                        0.0   \n",
            "2                        0.0                        0.0   \n",
            "3                        0.0                        0.0   \n",
            "4                        0.0                        0.0   \n",
            "\n",
            "   binary_trainingtype_1111  binary_trainingtype_11110  \\\n",
            "0                       0.0                        0.0   \n",
            "1                       0.0                        0.0   \n",
            "2                       0.0                        0.0   \n",
            "3                       0.0                        0.0   \n",
            "4                       0.0                        0.0   \n",
            "\n",
            "   binary_trainingtype_11111  \n",
            "0                        0.0  \n",
            "1                        0.0  \n",
            "2                        0.0  \n",
            "3                        0.0  \n",
            "4                        0.0  \n",
            "\n",
            "[5 rows x 56 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# List the columns you want to drop\n",
        "columns_to_drop = ['naam', 'trainingtype', '2k datum', 'binary_geslacht', 'binary_gewichtsklasse']\n",
        "\n",
        "# Drop the existing columns\n",
        "almost_clean_df = almost_clean_df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Columns to encode\n",
        "columns_to_encode = ['geslacht', 'gewichtsklasse', 'ervaring', 'binary_trainingtype']\n",
        "\n",
        "# Apply one-hot encoding\n",
        "encoded_data = encoder.fit_transform(almost_clean_df[columns_to_encode])\n",
        "encoded_columns = encoder.get_feature_names_out(columns_to_encode)\n",
        "\n",
        "# Create DataFrame for the encoded columns\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns)\n",
        "\n",
        "# Drop the columns that were encoded from almost_clean_df\n",
        "almost_clean_df = almost_clean_df.drop(columns=columns_to_encode)\n",
        "\n",
        "# Concatenate the one-hot encoded columns with the remaining data\n",
        "encoded_df = pd.concat([almost_clean_df, encoded_df], axis=1)\n",
        "\n",
        "# Print the resulting encoded dataframe\n",
        "print(encoded_df.head())\n",
        "encoded_df.to_csv('encoded_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "CO-zkm3Jv6Ek",
        "outputId": "f1bbbf02-b7f5-468d-ff2a-3bb3a0b35890"
      },
      "outputs": [],
      "source": [
        "# ### per persoon per training de gemiddelde 500_split berekenen\n",
        "\n",
        "# def gemid_split(data):\n",
        "#     data['year'] = pd.to_datetime(data['2k datum']).dt.year\n",
        "    \n",
        "#     data['unique_naam'] = data['naam'] + '_' + data['year'].astype(str)\n",
        "\n",
        "#     gemid_data = (data.groupby(['unique_naam', 'binary_trainingtype'], as_index=False).agg({'ervaring': 'first', 'geslacht': 'first', 'gewichtsklasse': 'first', '500_split': 'mean', '2k tijd': 'first', 'binary_geslacht': 'first', 'binary_gewichtsklasse': 'first'}))\n",
        "\n",
        "#     return gemid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def gemid_total(data):\n",
        "#     gemid_pp = (data.groupby(['unique_naam'], as_index=False).agg({'ervaring': 'first', '500_split': 'mean', '2k tijd': 'first', 'binary_geslacht': 'first', 'binary_gewichtsklasse': 'first'}))\n",
        "#     return gemid_pp\n",
        "\n",
        "# final_gemid_df = gemid_total(final_df)\n",
        "# print(final_gemid_df)\n",
        "# final_gemid_df.to_csv('final_gemid_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "OR_uCECY4yQY"
      },
      "outputs": [],
      "source": [
        "# ### een dictionary maken van alle gegevens per persoon; dit is meer voor ons overzicht en niet nodig voor het model\n",
        "\n",
        "# import json\n",
        "\n",
        "# def dict_per_naam(data):\n",
        "#   naam_dict = {}\n",
        "\n",
        "#   for i in range(len(data)):\n",
        "#       row = data.iloc[i].to_dict()\n",
        "\n",
        "#       for key, value in row.items():\n",
        "#           if isinstance(value, pd.Timestamp):\n",
        "#               row[key] = value.strftime('%Y-%m-%d')\n",
        "\n",
        "#       name = row.pop('unique_naam')\n",
        "#       constants = {key: row.pop(key) for key in ['ervaring', 'geslacht', 'gewichtsklasse', '2k tijd']}\n",
        "\n",
        "#       if name not in naam_dict:\n",
        "#           naam_dict[name] = {'gegevens': constants, 'tijden': []}\n",
        "\n",
        "#       naam_dict[name]['tijden'].append(row)\n",
        "\n",
        "#   print(json.dumps(naam_dict, indent=4, sort_keys=False))\n",
        "\n",
        "#   return naam_dict\n",
        "\n",
        "# new_namen_dict = dict_per_naam(new_dataframe)\n",
        "# gemid_new_namen_dict = dict_per_naam(final_df)\n",
        "# print(len(gemid_new_namen_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "a3zGA813ZQyL"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Data inladen\n",
        "# df = groot_gemid_df\n",
        "\n",
        "# # Eerst de data opschudden om bias te voorkomen\n",
        "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# # Zorg ervoor dat elke ervaring, geslacht en gewichtsklasse in elke set vertegenwoordigd zijn\n",
        "# train_data = pd.DataFrame()\n",
        "# val_data = pd.DataFrame()\n",
        "# test_data = pd.DataFrame()\n",
        "\n",
        "# for ervaring in df['ervaring'].unique():\n",
        "#     for geslacht in df['geslacht'].unique():\n",
        "#         for gewichtsklasse in df['gewichtsklasse'].unique():\n",
        "#             subset = df[(df['ervaring'] == ervaring) & (df['geslacht'] == geslacht) & (df['gewichtsklasse'] == gewichtsklasse)]\n",
        "#             if not subset.empty:\n",
        "#                 temp_train, temp_temp = train_test_split(subset, test_size=0.3, random_state=42)\n",
        "#                 temp_val, temp_test = train_test_split(temp_temp, test_size=0.5, random_state=42)\n",
        "#                 train_data = pd.concat([train_data, temp_train])\n",
        "#                 val_data = pd.concat([val_data, temp_val])\n",
        "#                 test_data = pd.concat([test_data, temp_test])\n",
        "\n",
        "# # Reset indexen\n",
        "# train_data.reset_index(drop=True, inplace=True)\n",
        "# val_data.reset_index(drop=True, inplace=True)\n",
        "# test_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# # Controleren op juiste verdeling\n",
        "# print(f\"Trainingsdata: {len(train_data)} rijen\")\n",
        "# print(f\"Validatiedata: {len(val_data)} rijen\")\n",
        "# print(f\"Testdata: {len(test_data)} rijen\")\n",
        "\n",
        "# # Optioneel: data opslaan in aparte bestanden\n",
        "# train_data.to_csv('train_data.csv', index=False)\n",
        "# val_data.to_csv('val_data.csv', index=False)\n",
        "# test_data.to_csv('test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "ZJOrsPxgYnL5"
      },
      "outputs": [],
      "source": [
        "# alles = tweek_naar_split(dataframe_op_sec)\n",
        "# print(alles)\n",
        "# print(len(alles))\n",
        "\n",
        "# min_value = alles.min()\n",
        "# filtered_alles = alles[alles!= min_value]\n",
        "\n",
        "# unique_values = alles.unique()\n",
        "# unique_values.sort()\n",
        "\n",
        "# first_min = unique_values[0]\n",
        "# second_min = unique_values[1]\n",
        "# third_min = unique_values[2]\n",
        "# fourth_min = unique_values[3]\n",
        "# eighth_min = unique_values[7]\n",
        "\n",
        "# print(first_min)\n",
        "# print(second_min)\n",
        "# print(third_min)\n",
        "# print(fourth_min)\n",
        "# print(eighth_min)\n",
        "\n",
        "# unique_values_desc = alles.unique()\n",
        "# unique_values_desc.sort()\n",
        "# unique_values_desc = unique_values_desc[::-1]\n",
        "\n",
        "# first_largest = unique_values_desc[0]\n",
        "# second_largest = unique_values_desc[1]\n",
        "# third_largest = unique_values_desc[2]\n",
        "# eighth_largest = unique_values_desc[7]\n",
        "\n",
        "# print(first_largest)\n",
        "# print(second_largest)\n",
        "# print(third_largest)\n",
        "# print(eighth_largest)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
