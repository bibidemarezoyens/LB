{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bibidemarezoyens/LB/blob/main/rowrowrow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UnXoqEc9ds24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_df = pd.read_excel('data_roeien.xlsx')"
      ],
      "metadata": {
        "id": "q2S_zKlyf4qd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "f133864a-0fa6-4b22-ef4c-e7fe47c3ad1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data_roeien.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-86108921de76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomplete_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_roeien.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_roeien.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def opschonen(data):\n",
        "    ### Onnodige kolommen verwijderen\n",
        "    complete_df = pd.read_excel(data)\n",
        "    clean_col_df = complete_df.drop(columns=['datum', 'ploeg', 'zone', 'intervaltype', 'interval_afstand', 'interval_tijd', 'interval_nummer', 'rust', 'machine', 'spm', '2k datum'], errors='ignore')\n",
        "\n",
        "    ### Lege strings omzetten naar NaN in de specifieke kolommen\n",
        "    clean_col_df['500_split'] = clean_col_df['500_split'].replace('', pd.NA)\n",
        "    clean_col_df['2k tijd'] = clean_col_df['2k tijd'].replace('', pd.NA)\n",
        "\n",
        "    ### Alleen rijen met lege '500_split' of '2k tijd' verwijderen\n",
        "    clean_row_df = clean_col_df.dropna(subset=['500_split', '2k tijd'])\n",
        "    clean_row_df.dropna(how='any',inplace=True)\n",
        "\n",
        "    ### Maak een kopie voor opschonen\n",
        "    clean_df = clean_row_df.copy()\n",
        "    clean_df.dropna(subset=['500_split', '2k tijd'])\n",
        "\n",
        "    ### Komma's naar punten veranderen in ‘500_split’ en ‘2k tijd’ columns en uren veranderen naar minuten (00:01:11.11 wordt 1:11.11)\n",
        "    for col in ['500_split', '2k tijd']:\n",
        "        print(clean_df[col])\n",
        "        clean_df[col] = clean_df[col].astype(str).str.strip()\n",
        "        clean_df[col] = clean_df[col].str.replace(',', '.', regex=False)\n",
        "        clean_df[col] = clean_df[col].str.lstrip('0')\n",
        "\n",
        "        # clean_df[col] = clean_df[col].astype(str).str.strip()\n",
        "        # clean_df[col] = clean_df[col].str.replace(',', '.', regex=False)\n",
        "        # clean_df[col] = clean_df[col].str.lstrip('0')\n",
        "        # clean_df[col] = clean_df[col].str.replace('^0:0', '', regex=True)\n",
        "        print(clean_df[col])\n",
        "\n",
        "    ### Verander 'trainingype' naar 'trainingtype'\n",
        "    clean_df = clean_df.rename(columns={'trainingype': 'trainingtype'})\n",
        "\n",
        "    return clean_df"
      ],
      "metadata": {
        "id": "-VuEps4qoZyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### de minuten veranderen naar seconden\n",
        "\n",
        "def time_to_seconds(time_str):\n",
        "    if pd.isna(time_str):\n",
        "        return None\n",
        "    try:\n",
        "        minutes, seconds = map(float, str(time_str).split(':'))\n",
        "        print('GOOD:', time_str)\n",
        "        return minutes * 60 + seconds\n",
        "    except ValueError:\n",
        "        print('ERROR:', time_str)\n",
        "        return None\n",
        "\n",
        "def verander_omzetting_seconden(docu):\n",
        "    docu['500_split'] = docu['500_split'].apply(time_to_seconds)\n",
        "    docu['2k tijd'] = docu['2k tijd'].apply(time_to_seconds)\n",
        "    return docu\n"
      ],
      "metadata": {
        "id": "zRyNU3YL4mAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groot_roeien_opgeschoond = opschonen('data_roeien.xlsx')\n",
        "klein_roeien_opgeschoond = opschonen('klein_roeien.xlsx')\n",
        "# print(groot_roeien_opgeschoond['500_split'].isnull().sum())\n"
      ],
      "metadata": {
        "id": "3qogGIOW4plM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(groot_roeien_opgeschoond['500_split'])"
      ],
      "metadata": {
        "id": "KTbil841y0Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groot_dataframe_op_sec = verander_omzetting_seconden(groot_roeien_opgeschoond)\n",
        "klein_dataframe_op_sec = verander_omzetting_seconden(klein_roeien_opgeschoond)\n",
        "\n",
        "print(groot_dataframe_op_sec['500_split'].isnull().sum())\n",
        "print(groot_roeien_opgeschoond['500_split'].isnull().sum())"
      ],
      "metadata": {
        "id": "YyOzR_V6xrRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(groot_dataframe_op_sec['500_split'].isnull().sum())\n",
        "print(groot_dataframe_op_sec[groot_dataframe_op_sec['500_split'].isnull()])\n",
        "groot_dataframe_op_sec.dropna(inplace=True)\n",
        "print(groot_dataframe_op_sec['500_split'].isnull().sum())\n",
        "print(groot_dataframe_op_sec['2k tijd'].isnull().sum())\n",
        "print(groot_dataframe_op_sec)\n",
        "\n",
        "groot_dataframe_op_sec.to_csv('verschoond_dataframe.csv', index=False)"
      ],
      "metadata": {
        "id": "ixobhcnk45Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def omzetten_trainingstype(data):\n",
        "    df = pd.read_excel(data)\n",
        "    print(df['trainingtype'].unique())\n",
        "\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(r\"/[a-zA-Z0-9']{3}\", \"\", regex=True)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\"1'\", 'minuutjes', regex=False)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\"1minuutjes\", \"11'\", regex=False)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\"'\", \"\", regex=False)\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\" \", \"\", regex=False)\n",
        "\n",
        "    df['trainingtype'] = df['trainingtype'].str.replace(\"r\", \"\", regex=False)\n",
        "\n",
        "\n",
        "\n",
        "    # df['trainingtype'] = df['trainingtype'].str.replace(\"3x15'\", '2', regex=False)\n",
        "    # df['trainingtype'] = df['trainingtype'].str.replace(\"3x2000m/5'r\", '3', regex=False)\n",
        "    # df['trainingtype'] = df['trainingtype'].str.replace(\"5x5'\", '1', regex=False)\n",
        "    # df['trainingtype'] = df['trainingtype'].str.replace(\"5x5'\", '1', regex=False)\n",
        "    print(df['trainingtype'].unique())\n",
        "\n",
        "    # df['trainingtype'] = pd.to_numeric(df['trainingtype'], errors='coerce')\n",
        "    # print(df['trainingtype'].unique())  # Inspect unique values\n",
        "    # df['trainingtype'].str.replace(\"5x5'\", \"1\" , regex=False)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JpCjn3AB-bi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(omzetten_trainingstype('verschoond_dataframe.xlsx'))"
      ],
      "metadata": {
        "id": "Zd05DWHe-kVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### per persoon per training de gemiddelde 500_split berekenen\n",
        "\n",
        "def gemid_split(data):\n",
        "\n",
        "    gemid_data = (data.groupby(['naam', 'trainingtype'], as_index=False).agg({'ervaring': 'first', 'geslacht': 'first', 'gewichtsklasse': 'first', '500_split': 'mean', '2k tijd': 'first'}))\n",
        "\n",
        "    return gemid_data\n",
        "\n",
        "klein_gemid_df = gemid_split(klein_dataframe_op_sec)\n",
        "print(klein_gemid_df)\n",
        "groot_gemid_df = gemid_split(groot_dataframe_op_sec)\n",
        "print(groot_gemid_df)"
      ],
      "metadata": {
        "id": "CO-zkm3Jv6Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### een dictionary maken van alle gegevens per persoon\n",
        "\n",
        "import json\n",
        "\n",
        "def dict_per_naam(data):\n",
        "  naam_dict = {}\n",
        "\n",
        "  for i in range(len(data)):\n",
        "      row = data.iloc[i].to_dict()\n",
        "\n",
        "      name = row.pop('naam')\n",
        "      constants = {key: row.pop(key) for key in ['ervaring', 'geslacht', 'gewichtsklasse', '2k tijd']}\n",
        "\n",
        "      if name not in naam_dict:\n",
        "          naam_dict[name] = {'gegevens': constants, 'tijden': []}\n",
        "\n",
        "      naam_dict[name]['tijden'].append(row)\n",
        "\n",
        "  print(json.dumps(naam_dict, indent=4, sort_keys=False))\n",
        "\n",
        "  return naam_dict\n",
        "\n",
        "klein_namen_dict = dict_per_naam(klein_dataframe_op_sec)\n",
        "gemid_klein_namen_dict = dict_per_naam(klein_gemid_df)"
      ],
      "metadata": {
        "id": "OR_uCECY4yQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groot_namen_dict = dict_per_naam(groot_dataframe_op_sec[:1000])\n",
        "# gemid_groot_namen_dict = dict_per_naam(groot_gemid_df)\n",
        "\n",
        "gemid_klein_namen_dict = dict_per_naam(klein_gemid_df)"
      ],
      "metadata": {
        "id": "_n793CyiR6LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Data inladen\n",
        "# df = groot_gemid_df\n",
        "\n",
        "# # Eerst de data opschudden om bias te voorkomen\n",
        "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# # Zorg ervoor dat elke ervaring, geslacht en gewichtsklasse in elke set vertegenwoordigd zijn\n",
        "# train_data = pd.DataFrame()\n",
        "# val_data = pd.DataFrame()\n",
        "# test_data = pd.DataFrame()\n",
        "\n",
        "# for ervaring in df['ervaring'].unique():\n",
        "#     for geslacht in df['geslacht'].unique():\n",
        "#         for gewichtsklasse in df['gewichtsklasse'].unique():\n",
        "#             subset = df[(df['ervaring'] == ervaring) & (df['geslacht'] == geslacht) & (df['gewichtsklasse'] == gewichtsklasse)]\n",
        "#             if not subset.empty:\n",
        "#                 temp_train, temp_temp = train_test_split(subset, test_size=0.3, random_state=42)\n",
        "#                 temp_val, temp_test = train_test_split(temp_temp, test_size=0.5, random_state=42)\n",
        "#                 train_data = pd.concat([train_data, temp_train])\n",
        "#                 val_data = pd.concat([val_data, temp_val])\n",
        "#                 test_data = pd.concat([test_data, temp_test])\n",
        "\n",
        "# # Reset indexen\n",
        "# train_data.reset_index(drop=True, inplace=True)\n",
        "# val_data.reset_index(drop=True, inplace=True)\n",
        "# test_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# # Controleren op juiste verdeling\n",
        "# print(f\"Trainingsdata: {len(train_data)} rijen\")\n",
        "# print(f\"Validatiedata: {len(val_data)} rijen\")\n",
        "# print(f\"Testdata: {len(test_data)} rijen\")\n",
        "\n",
        "# # Optioneel: data opslaan in aparte bestanden\n",
        "# train_data.to_csv('train_data.csv', index=False)\n",
        "# val_data.to_csv('val_data.csv', index=False)\n",
        "# test_data.to_csv('test_data.csv', index=False)"
      ],
      "metadata": {
        "id": "a3zGA813ZQyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tweek_naar_split(groot_dataframe_op_sec):\n",
        "    for i in range(len(groot_dataframe_op_sec['500_split'])):\n",
        "        if groot_dataframe_op_sec['500_split'].iloc[i] > 300:\n",
        "          groot_dataframe_op_sec['500_split'].iloc[i] = groot_dataframe_op_sec['500_split'].iloc[i] / 4\n",
        "    return groot_dataframe_op_sec['500_split']"
      ],
      "metadata": {
        "id": "_4MfYDIcGnbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alles = tweek_naar_split(groot_dataframe_op_sec)\n",
        "print(alles)\n",
        "print(len(alles))\n",
        "\n",
        "min_value = alles.min()\n",
        "filtered_alles = alles[alles!= min_value]\n",
        "\n",
        "unique_values = alles.unique()\n",
        "unique_values.sort()\n",
        "\n",
        "first_min = unique_values[0]\n",
        "second_min = unique_values[1]\n",
        "third_min = unique_values[2]\n",
        "fourth_min = unique_values[3]\n",
        "eighth_min = unique_values[7]\n",
        "\n",
        "print(first_min)\n",
        "print(second_min)\n",
        "print(third_min)\n",
        "print(fourth_min)\n",
        "print(eighth_min)\n",
        "\n",
        "unique_values_desc = alles.unique()\n",
        "unique_values_desc.sort()\n",
        "unique_values_desc = unique_values_desc[::-1]\n",
        "\n",
        "first_largest = unique_values_desc[0]\n",
        "second_largest = unique_values_desc[1]\n",
        "third_largest = unique_values_desc[2]\n",
        "eighth_largest = unique_values_desc[7]\n",
        "\n",
        "print(first_largest)\n",
        "print(second_largest)\n",
        "print(third_largest)\n",
        "print(eighth_largest)"
      ],
      "metadata": {
        "id": "ZJOrsPxgYnL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(groot_dataframe_op_sec):\n",
        "  alles = tweek_naar_split(groot_dataframe_op_sec)\n",
        "  alles = alles[alles >= 80]\n",
        "  return alles\n",
        "print(len(alles))"
      ],
      "metadata": {
        "id": "gJX39SPsU-nP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}