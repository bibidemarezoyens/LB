{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ervaring  500_split  2k tijd  binary_trainingtype  binary_geslacht  \\\n",
      "0         1      104.6    379.9                    0                0   \n",
      "1         1      104.7    379.9                    0                0   \n",
      "2         1      104.3    379.9                    0                0   \n",
      "3         1      104.0    379.9                    0                0   \n",
      "4         1      104.1    379.9                    0                0   \n",
      "\n",
      "   binary_gewichtsklasse  \n",
      "0                      1  \n",
      "1                      1  \n",
      "2                      1  \n",
      "3                      1  \n",
      "4                      1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_df.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdata: 3018 rijen\n",
      "Validatiedata: 905 rijen\n",
      "Testdata: 391 rijen\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Eerst de data opschudden om bias te voorkomen\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Zorg ervoor dat elke ervaring, geslacht en gewichtsklasse in elke set vertegenwoordigd zijn\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for ervaring in df['ervaring'].unique():\n",
    "    for geslacht in df['binary_geslacht'].unique():\n",
    "        for gewichtsklasse in df['binary_gewichtsklasse'].unique():\n",
    "            subset = df[(df['ervaring'] == ervaring) & (df['binary_geslacht'] == geslacht) & (df['binary_gewichtsklasse'] == gewichtsklasse)]\n",
    "            if not subset.empty:\n",
    "                temp_train, temp_temp = train_test_split(subset, test_size=0.3, random_state=42)\n",
    "                temp_val, temp_test = train_test_split(temp_temp, test_size=0.3, random_state=42)\n",
    "                train_data = pd.concat([train_data, temp_train])\n",
    "                val_data = pd.concat([val_data, temp_val])\n",
    "                test_data = pd.concat([test_data, temp_test])\n",
    "\n",
    "# Reset indexen\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Controleren op juiste verdeling\n",
    "print(f\"Trainingsdata: {len(train_data)} rijen\")\n",
    "print(f\"Validatiedata: {len(val_data)} rijen\")\n",
    "print(f\"Testdata: {len(test_data)} rijen\")\n",
    "\n",
    "X_train = train_data.drop(columns=['2k tijd'])\n",
    "y_train = train_data['2k tijd']\n",
    "\n",
    "X_val = val_data.drop(columns=['2k tijd'])\n",
    "y_val = val_data['2k tijd']\n",
    "\n",
    "X_test = test_data.drop(columns=['2k tijd'])\n",
    "y_test = test_data['2k tijd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIDGE REGRESSION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE (zonder tuning): 488.1280127159293\n",
      "Validation R-squared (zonder tuning): 0.5228237960506925\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=  19.3s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  31.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  22.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  24.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  40.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  32.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  35.0s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  11.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  24.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  25.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  36.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  35.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  25.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   9.0s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  15.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  14.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  17.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  38.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  32.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  41.4s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   1.7s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  15.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  14.1s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  29.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  30.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  36.9s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   1.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  55.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  39.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=  12.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=  26.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   1.1s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  38.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=  37.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=  12.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   1.2s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  25.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=  25.8s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   1.0s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   0.9s\n",
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  32.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_base.py:172: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   5.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   5.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   5.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   5.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   5.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   7.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   9.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   8.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   8.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   9.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   8.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   8.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   6.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   7.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   8.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   6.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   7.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   8.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   6.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   7.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   6.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   7.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   9.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   6.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   7.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   8.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   7.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  10.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  18.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  17.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  18.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  25.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  21.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  18.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  18.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  16.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  13.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  14.2s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  19.4s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  15.3s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  12.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  16.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  12.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   5.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   7.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   6.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   6.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   5.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   6.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   7.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   7.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   8.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   9.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   6.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   9.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   6.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   6.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   6.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   6.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   7.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   5.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   5.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   5.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   5.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   5.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   6.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   7.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   5.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   5.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   6.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   5.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   5.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  12.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  14.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  15.7s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  18.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  15.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  19.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  18.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  11.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  13.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  13.8s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  13.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  11.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  13.5s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  13.4s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.001, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=adam; total time=   5.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   7.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   5.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=adam; total time=   7.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   6.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=   9.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=adam; total time=  11.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   8.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  11.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   8.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  11.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  11.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   8.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  11.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(50,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   8.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=adam; total time=   8.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   7.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   8.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=adam; total time=   9.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   8.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=adam; total time=   9.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   8.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   8.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=adam; total time=   9.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   8.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   7.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=adam; total time=   9.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   7.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   8.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=adam; total time=   9.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100,), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  17.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=adam; total time=  18.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=1000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  20.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  25.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=adam; total time=  21.6s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.5s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=2000, solver=sgd; total time=   0.4s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  14.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  15.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=adam; total time=  13.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=constant, max_iter=3000, solver=sgd; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=adam; total time=  10.7s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=1000, solver=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  11.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  15.3s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=adam; total time=  13.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=2000, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  12.2s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  15.1s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=adam; total time=  12.9s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, alpha=0.01, hidden_layer_sizes=(100, 50), learning_rate=adaptive, max_iter=3000, solver=sgd; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "54 fits failed out of a total of 648.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 751, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 495, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/imme/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [-6.57736421e+02 -4.55302770e+23 -6.57736421e+02 -4.55302770e+23\n",
      " -6.57736421e+02 -4.55302770e+23 -6.57736421e+02 -2.02922011e+23\n",
      " -6.57736421e+02 -2.02922011e+23 -6.57736421e+02 -2.02922011e+23\n",
      " -5.44814892e+02 -1.44649367e+24 -5.44814892e+02 -1.44649367e+24\n",
      " -5.44814892e+02 -1.44649367e+24 -5.44814892e+02 -6.44681789e+23\n",
      " -5.44814892e+02 -6.44681789e+23 -5.44814892e+02 -6.44681789e+23\n",
      " -1.26931612e+03             nan -1.26931612e+03             nan\n",
      " -1.26931612e+03             nan -1.26931612e+03             nan\n",
      " -1.26931612e+03             nan -1.26931612e+03             nan\n",
      " -5.86368709e+02 -4.55302770e+23 -5.86368709e+02 -4.55302770e+23\n",
      " -5.86368709e+02 -4.55302770e+23 -5.86368709e+02 -2.02922011e+23\n",
      " -5.86368709e+02 -2.02922011e+23 -5.86368709e+02 -2.02922011e+23\n",
      " -8.04186108e+02 -1.44649367e+24 -8.04186108e+02 -1.44649367e+24\n",
      " -8.04186108e+02 -1.44649367e+24 -8.04186108e+02 -6.44681789e+23\n",
      " -8.04186108e+02 -6.44681789e+23 -8.04186108e+02 -6.44681789e+23\n",
      " -1.52171915e+04             nan -1.52171915e+04             nan\n",
      " -1.52171915e+04             nan -1.52171915e+04             nan\n",
      " -1.52171915e+04             nan -1.52171915e+04             nan\n",
      " -5.08852792e+02 -4.55302770e+23 -5.08852792e+02 -4.55302770e+23\n",
      " -5.08852792e+02 -4.55302770e+23 -5.08852792e+02 -2.02922011e+23\n",
      " -5.08852792e+02 -2.02922011e+23 -5.08852792e+02 -2.02922011e+23\n",
      " -6.86664861e+02 -1.44649367e+24 -6.86664861e+02 -1.44649367e+24\n",
      " -6.86664861e+02 -1.44649367e+24 -6.86664861e+02 -6.44681789e+23\n",
      " -6.86664861e+02 -6.44681789e+23 -6.86664861e+02 -6.44681789e+23\n",
      " -1.08309566e+03             nan -1.08309566e+03             nan\n",
      " -1.08309566e+03             nan -1.08309566e+03             nan\n",
      " -1.08309566e+03             nan -1.08309566e+03             nan\n",
      " -4.92343877e+03 -1.34254616e+03 -2.09982952e+03 -1.34254616e+03\n",
      " -2.09982952e+03 -1.34254616e+03 -4.92343877e+03 -1.34116728e+03\n",
      " -2.09982952e+03 -1.34116728e+03 -2.09982952e+03 -1.34116728e+03\n",
      " -1.45750480e+03 -1.35156409e+03 -1.32055560e+03 -1.35156409e+03\n",
      " -1.32055560e+03 -1.35156409e+03 -1.45750480e+03 -1.34196687e+03\n",
      " -1.32055560e+03 -1.34196687e+03 -1.32055560e+03 -1.34196687e+03\n",
      " -4.48555984e+04 -1.36543331e+03 -1.04793371e+03 -1.36543331e+03\n",
      " -1.04793371e+03 -1.36543331e+03 -1.28167726e+03 -1.36323274e+03\n",
      " -1.04793371e+03 -1.36323274e+03 -1.04793371e+03 -1.36323274e+03\n",
      " -4.77000358e+03 -1.32615547e+03 -1.71170621e+03 -1.32615547e+03\n",
      " -1.71170621e+03 -1.32615547e+03 -4.77000358e+03 -1.33807719e+03\n",
      " -1.71170621e+03 -1.33807719e+03 -1.71170621e+03 -1.33807719e+03\n",
      " -1.33051113e+03 -1.30331533e+03 -1.33051113e+03 -1.30331533e+03\n",
      " -1.33051113e+03 -1.30331533e+03 -1.33051113e+03 -1.33999530e+03\n",
      " -1.33051113e+03 -1.33999530e+03 -1.33051113e+03 -1.33999530e+03\n",
      " -1.27895702e+03 -1.36543327e+03 -1.09633931e+03 -1.36543327e+03\n",
      " -1.09633931e+03 -1.36543327e+03 -1.27895702e+03 -1.36323270e+03\n",
      " -1.09633931e+03 -1.36323270e+03 -1.09633931e+03 -1.36323270e+03\n",
      " -3.47615213e+03 -1.33930580e+03 -1.77681401e+03 -1.33930580e+03\n",
      " -1.77681401e+03 -1.33930580e+03 -3.47615213e+03 -1.33402296e+03\n",
      " -1.77681401e+03 -1.33402296e+03 -1.77681401e+03 -1.33402296e+03\n",
      " -1.42877511e+03 -1.36407794e+03 -1.42877511e+03 -1.36407794e+03\n",
      " -1.42877511e+03 -1.36407794e+03 -1.42877511e+03 -1.34615807e+03\n",
      " -1.42877511e+03 -1.34615807e+03 -1.42877511e+03 -1.34615807e+03\n",
      " -1.31171641e+03 -1.36543282e+03 -1.02078066e+03 -1.36543282e+03\n",
      " -1.02078066e+03 -1.36543282e+03 -1.31171641e+03 -1.36323234e+03\n",
      " -1.02078066e+03 -1.36323234e+03 -1.02078066e+03 -1.36323234e+03]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV:\n",
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 1000, 'solver': 'adam'}\n",
      "Test MSE (na tuning): 2346.616002117587\n",
      "Test RMSE (na tuning): 48.4418827268056\n",
      "Test R-squared (na tuning): -1.2851088246488604\n"
     ]
    }
   ],
   "source": [
    "# NEURAL NETWORK\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = mlp.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation MSE (zonder tuning): {val_mse}\")\n",
    "print(f\"Validation R-squared (zonder tuning): {val_r2}\")\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50, 25, 20), (100,), (100, 50)],\n",
    "    'activation': ['relu', 'identity'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'max_iter': [1000, 2000, 3000]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=MLPRegressor(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=3,\n",
    "                           verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from grid search\n",
    "print(\"Best parameters from GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Use the best model from grid search\n",
    "best_mlp = grid_search.best_estimator_\n",
    "\n",
    "# Test the final model on the test data\n",
    "y_test_pred = best_mlp.predict(X_test)\n",
    "test_mse_nn = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse_nn = test_mse_nn ** 0.5\n",
    "test_r2_nn = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test MSE (na tuning): {test_mse_nn}\")\n",
    "print(f\"Test RMSE (na tuning): {test_rmse_nn}\")\n",
    "print(f\"Test R-squared (na tuning): {test_r2_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE (zonder tuning): 66.50744379765271\n",
      "Validation R-squared (zonder tuning): 0.9349847401931329\n",
      "Best parameters from GridSearchCV:\n",
      "{'colsample_bytree': 1.0, 'learning_rate': 1.5, 'max_depth': 5, 'min_child_weight': 7, 'n_estimators': 100, 'reg_lambda': 500}\n",
      "Test MSE (na tuning): 53.433444833608675\n",
      "Test RMSE (na tuning): 7.309818385815661\n",
      "Test R-squared (na tuning): 0.9479670997681414\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = xgb.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation MSE (zonder tuning): {val_mse}\")\n",
    "print(f\"Validation R-squared (zonder tuning): {val_r2}\")\n",
    "\n",
    "param_grid = {'reg_lambda': [0.1, 1, 10, 100, 150, 500], \n",
    "              'min_child_weight': [1, 3, 5, 7, 9, 12], \n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1, 1.2, 1.5],\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'n_estimators': [100, 200, 300, 400, 500]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=XGBRegressor(), \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           cv=3, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from grid search\n",
    "print(\"Best parameters from GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Use the best model from grid search\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Test the final model on the test data\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "test_mse_xgb = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse_xgb = test_mse_xgb ** 0.5\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test MSE (na tuning): {test_mse_xgb}\")\n",
    "print(f\"Test RMSE (na tuning): {test_rmse_xgb}\")\n",
    "print(f\"Test R-squared (na tuning): {test_r2_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
