{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ervaring  500_split  2k tijd  binary_trainingtype  binary_geslacht  \\\n",
      "0       1.0      104.6    379.9                    0                0   \n",
      "1       1.0      104.7    379.9                    0                0   \n",
      "2       1.0      104.3    379.9                    0                0   \n",
      "3       1.0      104.0    379.9                    0                0   \n",
      "4       1.0      104.1    379.9                    0                0   \n",
      "\n",
      "   binary_gewichtsklasse  \n",
      "0                      1  \n",
      "1                      1  \n",
      "2                      1  \n",
      "3                      1  \n",
      "4                      1  \n",
      "Trainingsdata: 3018 rijen\n",
      "Validatiedata: 905 rijen\n",
      "Testdata: 391 rijen\n",
      "371.8\n",
      "510.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Data inladen\n",
    "df = pd.read_csv(\"final_df.csv\")\n",
    "print(df.head())\n",
    "# df = groot_gemid_df\n",
    "\n",
    "# Eerst de data opschudden om bias te voorkomen\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Zorg ervoor dat elke ervaring, geslacht en gewichtsklasse in elke set vertegenwoordigd zijn\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for ervaring in df['ervaring'].unique():\n",
    "    for geslacht in df['binary_geslacht'].unique():\n",
    "        for gewichtsklasse in df['binary_gewichtsklasse'].unique():\n",
    "            subset = df[(df['ervaring'] == ervaring) & (df['binary_geslacht'] == geslacht) & (df['binary_gewichtsklasse'] == gewichtsklasse)]\n",
    "            if not subset.empty:\n",
    "                temp_train, temp_temp = train_test_split(subset, test_size=0.3, random_state=42)\n",
    "                temp_val, temp_test = train_test_split(temp_temp, test_size=0.3, random_state=42)\n",
    "                train_data = pd.concat([train_data, temp_train])\n",
    "                val_data = pd.concat([val_data, temp_val])\n",
    "                test_data = pd.concat([test_data, temp_test])\n",
    "\n",
    "# Reset indexen\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Controleren op juiste verdeling\n",
    "print(f\"Trainingsdata: {len(train_data)} rijen\")\n",
    "print(f\"Validatiedata: {len(val_data)} rijen\")\n",
    "print(f\"Testdata: {len(test_data)} rijen\")\n",
    "\n",
    "# Optioneel: data opslaan in aparte bestanden\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "val_data.to_csv('val_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)\n",
    "\n",
    "print(df['2k tijd'].min())\n",
    "print(df['2k tijd'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['2k tijd'])\n",
    "y_train = train_data['2k tijd']\n",
    "\n",
    "X_val = val_data.drop(columns=['2k tijd'])\n",
    "y_val = val_data['2k tijd']\n",
    "\n",
    "X_test = test_data.drop(columns=['2k tijd'])\n",
    "y_test = test_data['2k tijd']\n",
    "\n",
    "#maakt geen verschil\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 67.01244653711882\n",
      "mse_val = 75.06177185004438\n",
      "rse = 8.186113029827943\n",
      "[417.47504]\n",
      "[428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867 428.10867\n",
      " 428.10867 428.10867 428.10867 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504\n",
      " 417.47504 417.47504 417.47504 417.47504 417.47504 417.47504]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42, reg_lambda=100)\n",
    "\n",
    "predictions = xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "val_pred = xgb_model.predict(X_val_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mse_val = mean_squared_error(y_val, val_pred)\n",
    "print(f\"mse = {mse}\")\n",
    "print(f\"mse_val = {mse_val}\")\n",
    "\n",
    "rse = np.sqrt(mse)\n",
    "print(f\"rse = {rse}\")\n",
    "\n",
    "predictions = xgb_model.predict(X_test)\n",
    "prediction1 = xgb_model.predict(np.array([[1, 104.6, 0, 0, 1]]))\n",
    "print(prediction1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda (reg_lambda): 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {'reg_lambda': [0.1, 1, 10, 100, 150, 500]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best lambda (reg_lambda):\", grid_search.best_params_['reg_lambda'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
